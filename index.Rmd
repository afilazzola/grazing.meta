---
title: A meta-analysis fo the multi-trophic effects of grazing
author: ""
date: "2018"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
---
<br>  

### Grazing effects are multi-trophic through mediating plant composition: a meta-analysis
<br>  

![](./grazing.jpg)
<br> 

[Alessandro Filazzola](http://www.filazzola.info/), Batbaatar Amgaa,  Charlotte Brown, Issac Heida, Jessica Grenke, Margarete Dettlaff, Tan Bao, & [JC Cahill](https://grad.biology.ualberta.ca/cahill/)


```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(PRISMAstatement)
```

### Purpose

Conduct a meta-analysis of the literature testing the indirect effects of grazing on animal taxa's through the direct effects on the plant community. 

### Objectives

1. 
2. 

### Timeline

date    | task
------------------|--------------------------------------------------
Nov 9 | Establish search terms to be used in the meta-analysis
Nov 12 | Compile list of journal artcles and sub-divide for each researcher
Nov 14  | Begin reviewing papers and extracting data
Jan 28  | Complete data extraction from papers
Feb 11  | Complete preliminary analysis and set structure for MS
Feb 25 | Settle on analyses to be used and begin writing manuscript
March 11 | Complete first draft of MS and pass to co-authors
March 25 | Comments passed back on draft
April 2 | Complete revisions and submit to journal


### Literature Review - 1. Search

#### Search Terms

A systematic literature search was conducted using Web of Science for all emperical research articles.  The review will include all studies globally. The intended purpose of this search is to capture all articles that have documented grazing either along a gradient (e.g. different frequencies or intensity) or presence/absence (e.g. excluded, ungrazed, or retired ranch lands). We condcuted two separate searches to capture studies that tested gradients and studies that compared grazing to ungrazed treatments. Duplicate articles between the searches were removed. We also intentionally excluded terms that  resulted in articles not relevant to the purpose of this study including: review, synthesis, policy, social, carbon, and fish. The search terms that used were: 

**Search A**
`graz* OR livestock` **AND**  `exclosure* OR exclusion OR exclude* OR ungrazed OR retire* OR fallow*`

**Search B**
`grazing intensity OR grazing gradient OR stocking rate OR rotation* grazing`


### Literature Review - 2. Sort

This steps includes a. checking for duplicating, b. reviewing each instance for relevancy, c. consistently identifying and documenting exclusion criteria. Outcomes include a list of publications to be used for synthesis, a library of pdfs, and a PRISMA report to ensure the worflow is transparent and reproducible. Papers were excluded with the following characteristics:

- Not emperical study (e.g. review, book chapter)
- Irrelevant categories (e.g. political science, law, sports tourism, art)

#### Reasons for exclusion
```{r, warning=FALSE, message=FALSE}
evidence <- read.csv("data//synthesisdata//evidence.csv")
### Identify studies that were excluded
excludes <- evidence %>% group_by(reason.simplified) %>% count(exclude) %>% filter(reason.simplified!="")
ggplot(excludes, aes(x=reason.simplified, y=n)) + geom_bar(stat="identity") + coord_flip()

## frequency of study
year.rate <- evidence %>% group_by(Publication.Year) %>% summarize(n=length(Publication.Year))

ggplot(tail(year.rate,30)) + geom_bar(aes(x=Publication.Year, y=n), stat="identity") + ylab("number of published studies") +xlab("year published") +theme(text = element_text(size=16))
```


#### Prisma report

```{r}
## total number of papers found
nrow(evidence)

## number of papers found outside of WoS
other <- read.csv("data/synthesisdata//other.sources.csv")
nrow(other)

## number of articles excluded
excludes <- evidence %>% filter(exclude=="yes")
nrow(excludes)

## relevant papers
review <- evidence %>% filter(exclude!="yes")
nrow(review)

## papers for meta
datasets <- read.csv("data//binary.simplified.csv")
meta <- length(unique(datasets$uniqueID))
meta

prisma(found = 2989,
       found_other = 1,
       no_dupes = 2989,
       screened = 2989,
       screen_exclusions = 2675,
       full_text = 315,
       full_text_exclusions = 0,
       qualitative = 315, 
       quantitative = 216,
       width = 800, height = 800)
```


#### Patterns of GI Studies Globally
```{r warning=FALSE, message=FALSE, fig.width=12, fig.height=10}
require(ggmap)
###  Start with base map of world
mp <- NULL
mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
mp <- ggplot() +   mapWorld

## colorblind-friendly palette
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","#000000")

meta <- read.csv("data//synthesisdata//evidence.csv")
meta <- meta %>% filter(lat != "") ## remove blanks for lat and lon
meta <- meta[!grepl(";", meta$lat),] ## remove multiple entries
meta$lat <- as.numeric(levels(meta$lat))[meta$lat] ## convert from factor to number
meta$lon <- as.numeric(levels(meta$lon))[meta$lon] ## convert from factor to number


## plot points on top
mp <- mp+ geom_point(data=meta , aes(x=lon, y=lat), size=2) 
mp

```


### 3. Synthesis - Abundance

```{r}
meta <- read.csv("data//binary.simplified.csv")
  
  
## Load packages and functions
library(reshape2)
library(metafor)
source("meta.eval.r") ## Multiple aggregate
  
    
  ## Simplify the estimates column
  meta2 <- meta
  est <- read.csv("data//Unique.Estimates.Column.csv")
  meta2 <- merge(meta2, est, by="Estimate")
  
  ## drop Lichen, Microbes and fungi
    meta2 <- meta2 %>% filter(Functional.Group != "Producer") %>% filter(Higher.Taxa != "Microbial") ## examine animals only
  
  ## join manuscript data
  ms.data <- read.csv("data//synthesisdata//manuscript.data.csv")
  meta2 <- merge(meta2, ms.data, by="uniqueID")
  ## subset for abundance only
  meta2 <- meta2 %>% filter(est.reduced == "abundance")
  meta2[,"functional.taxa"] <- paste0(meta2$Higher.Taxa, meta2$Functional.Group)
    
  ## Create Unique identifier column
  meta2[,"UniqueSite"] <- paste(meta2$uniqueID, meta2$Higher.Taxa, meta2$Taxa, meta2$functional.taxa, meta2$estimate.simplified, sep="-")
  
  ## convert se to sd
  meta2[meta2$Stat=="se","Value"] <- meta2[meta2$Stat=="se","Value"] * 1.96
  meta2[meta2$Stat=="se","Stat"] <- "sd"
  
  ## drop comparisons that are not pairwise
  meta2 <-  meta2 %>% filter(grazing.reduced == "ungrazed" | grazing.reduced == "grazed")
  meta2 <- meta2 %>% filter(uniqueID != "30") %>% ## drop study 30 because anomalous 
  filter(uniqueID != "111") ## data is missing in study 111
  
  ## Drop anomalous studies
  meta2 <- meta2 <- meta2 %>% filter(!uniqueID %in% c("654", "1660")) ## native grazer not ungulate
  
  ## Test one higher taxa at a time
  meta2 <- meta2 %>% filter(Functional.Group != "Other")
  
  ## Test domestic grazers only
  meta2 <- meta2 %>% filter(grazer.simplified %in% c("domestic","both"))

    ## Use function to extract summary statistics for comparisons
  ## meta.eval  arguments are (meta.data, compare, ids , stats)
  grazed.compare <- meta.eval(meta2, grazing.reduced, UniqueSite, Stat)
  
  ## Combine the lists into same dataframe
  ## Rename Columns in second dataframe
  grazed.stat <- grazed.compare [[2]] ## extracted statistics 
  names(grazed.stat) <- c("UniqueSite","grazed_mean","grazed_sd","ungrazed_mean","ungrazed_sd","grazed_n","ungrazed_n") ## rename columns to match
  grazed.raw <- grazed.compare[[1]] ## calculated statistics from raw values
  
  ## Join two dataframes
  meta.stat <- rbind(grazed.raw, grazed.stat[, names(grazed.raw)])
  
  
  meta.ready <- escalc(n1i = ungrazed_n, n2i = grazed_n, m1i = ungrazed_mean, m2i = grazed_mean, sd1i = ungrazed_sd, sd2i = grazed_sd, data = meta.stat, measure = "SMD", append = TRUE)
  
  ## clean up meta.ready
  meta.ready <- na.omit(meta.ready) ## drop NAs
  meta.ready <- meta.ready[meta.ready$grazed_mean<80,] ## Drop extreme high variance
  
  
  ## separate out the identifiers
  siteID <- matrix(unlist(strsplit(meta.ready$UniqueSite,"-")),ncol=5, byrow=TRUE)
  siteID <- data.frame(siteID) ## recreate as dataframe
  colnames(siteID) <- c("Study","higher.taxa","taxa","FG","measure") ## add column names
  meta.ready <- cbind(data.frame(meta.ready), siteID)
  
  #random-effects meta-analysis for grazed vs ungrazed plots
  m1 <- rma(yi=yi, vi=vi,  data = meta.ready)
  summary(m1) 
  
  ## get last year grazed as covariate
  yr.grazed <- meta2 %>% group_by(uniqueID) %>% summarize(yr=max(yr.grazed))
  colnames(yr.grazed)[1] <- "Study"
  site.yr <- merge(siteID, yr.grazed, by="Study")
  meta.ready[,"yr.grazed"] <- site.yr$yr
  meta.ready[,"previously.grazed"] <- as.factor(ifelse(is.na(meta.ready$yr.grazed),0,1))
  
  #mixed-effects meta-analysis for grazed vs ungrazed plots
  m2 <- rma(yi=yi, vi=vi, mods=~ -1 + FG,  data = meta.ready)
  summary(m2) 

  #write.csv(meta.ready, "data//effectSize//div.animal.csv", row.names=FALSE)

## compare inclusion of moderators
(.9539-.9352)/.9352 ## explains an additional 2%

## Produce a forest plot to determine the effect sizes for each study
forest(m2)
regtest(m2)
confint(m1)


## Check for publication bias
## The symetrical distriubtion suggests there is no publication bias
funnel(m2)

## Calculate rosenthals Failsafe number
fsn(yi, vi, data=meta.ready)

# ## generate plot with spaces inbetween
# forest(m1, atransf=exp, cex=0.75, ylim=c(-1, 24),
#        order=order(meta.ready$GI.compare,meta.ready$taxa), rows=c(3:4,7,10:16,19:21),
# #         mlab="RE model for all studies", psize=1, slab= paste(meta.ready$Study, meta.ready$taxa, meta.ready$measure))
# 
# addpoly(res.w, row=18, cex=0.75, atransf=exp, mlab="RE model for green wall")
# addpoly(res.r, row= 9, cex=0.75, atransf=exp, mlab="RE model for green roof")
# addpoly(res.rd, row= 6, cex=0.75, atransf=exp, mlab="RE model for roadsides")
# addpoly(res.p, row= 2, cex=0.75, atransf=exp, mlab="RE model for retention ponds")

```


### Testing the effects of grazing on producers
```{r}
meta <- read.csv("data//plantAnalysis.csv")
meta2 <- meta
  
## Load packages and functions
library(reshape2)
library(metafor)
source("meta.eval.r") ## Multiple aggregate
  
  
  
  ## join manuscript data
  ms.data <- read.csv("data//synthesisdata//manuscript.data.csv")
  meta2 <- merge(meta2, ms.data, by="uniqueID")

  ## Drop mychoriza because only two studies
  
    ## Create Unique identifier column
  meta2 <- meta2 %>% filter(estimate.simplified != "omit")
  meta2[,"UniqueSite"] <- paste(meta2$uniqueID, meta2$Taxa, meta2$estimate.simplified, sep="-")
  
  ## convert se to sd
  meta2[meta2$Stat=="se","Value"] <- meta2[meta2$Stat=="se","Value"] * 1.96
  meta2[meta2$Stat=="se","Stat"] <- "sd"
  
  ## drop comparisons that are not pairwise
  meta2 <-  meta2 %>% filter(grazing.reduced == "ungrazed" | grazing.reduced == "grazed")
  meta2 <- meta2 %>% filter(uniqueID != "30") ## drop study 30 because anomalous 
  
  ## Drop anomalous studies
  meta2 <- meta2 <- meta2 %>% filter(!uniqueID %in% c("654", "1660")) ## native grazer not ungulate
  

  ## Test domestic grazers only
  meta2 <- meta2 %>% filter(grazer.simplified %in% c("domestic","both"))


    ## Use function to extract summary statistics for comparisons
  ## meta.eval  arguments are (meta.data, compare, ids , stats)
  grazed.compare <- meta.eval(meta2, grazing.reduced, UniqueSite, Stat)
  
  ## Combine the lists into same dataframe
  ## Rename Columns in second dataframe
  grazed.stat <- grazed.compare [[2]] ## extracted statistics 
  names(grazed.stat) <- c("UniqueSite","grazed_mean","grazed_sd","ungrazed_mean","ungrazed_sd","grazed_n","ungrazed_n") ## rename columns to match
  grazed.raw <- grazed.compare[[1]] ## calculated statistics from raw values
  
  ## Join two dataframes
  meta.stat <- rbind(grazed.raw, grazed.stat[, names(grazed.raw)])
  
  
  meta.ready <- escalc(n1i = ungrazed_n, n2i = grazed_n, m1i = ungrazed_mean, m2i = grazed_mean, sd1i = ungrazed_sd, sd2i = grazed_sd, data = meta.stat, measure = "SMD", append = TRUE)
  
  ## clean up meta.ready
  meta.ready <- na.omit(meta.ready) ## drop NAs
  meta.ready <- meta.ready[meta.ready$grazed_mean<80,] ## Drop extreme high variance
  
  
  ## separate out the identifiers
  siteID <- matrix(unlist(strsplit(meta.ready$UniqueSite,"-")),ncol=3, byrow=TRUE)
  siteID <- data.frame(siteID) ## recreate as dataframe
  colnames(siteID) <- c("Study","taxa","measure") ## add column names
  meta.ready <- cbind(data.frame(meta.ready), siteID)
  
  #random-effects meta-analysis for grazed vs ungrazed plots
  m1 <- rma(yi=yi, vi=vi,  data = meta.ready)
  summary(m1) 
  
  ## get last year grazed as covariate
  yr.grazed <- meta2 %>% group_by(uniqueID) %>% summarize(yr=max(yr.grazed))
  colnames(yr.grazed)[1] <- "Study"
  site.yr <- merge(siteID, yr.grazed, by="Study")
  meta.ready[,"yr.grazed"] <- site.yr$yr
  meta.ready[,"previously.grazed"] <- as.factor(ifelse(is.na(meta.ready$yr.grazed),0,1))
  
  #mixed-effects meta-analysis for grazed vs ungrazed plots
  m2 <- rma(yi=yi, vi=vi, mods=~ -1 + measure ,  data = meta.ready)
  summary(m2) 
  


```



### Compare regional patterns
```{r}

## Load in effect sizes
occurdat<-list.files("data//effectSize",pattern=".csv$",full=T)
animal.abd <- read.csv(occurdat[1])
colnames(animal.abd)[colnames(animal.abd)=="Study"] <- "uniqueID"
 
## join manuscript data
ms.data <- read.csv("data//synthesisdata//manuscript.data.csv")
meta3 <- merge(animal.abd, ms.data, by="uniqueID")

library(raster)

## Convert lat lon to spatial points
meta3 <- meta3 %>% filter(lat != "") ## remove blanks for lat and lon
meta3 <- meta3[!grepl(";", meta3$lat),] ## remove multiple entries
meta3$lat <- as.numeric(levels(meta3$lat))[meta3$lat] ## convert from factor to number
meta3$lon <- as.numeric(levels(meta3$lon))[meta3$lon] ## convert from factor to number

## generate dataframe
gps <- data.frame(uniqueID = meta3$uniqueID, lon=meta3$lon, lat=meta3$lat)
gps <- gps[!duplicated(gps$uniqueID),]


## assign spatial points
crs.world <-CRS("+proj=longlat +datum=WGS84")
coordinates(gps) <- ~lon+lat
proj4string(gps) <- crs.world

## load rasters
temp <- raster("L:\\Climaterasters\\bio1.tif")
prec <- raster("L:\\Climaterasters\\bio12.tif")

clim <- stack(temp,prec)


## extract temperature and preciptiation
gps.clim <- data.frame(extract(clim, gps))
gps.clim["uniqueID"] <- gps$uniqueID


## compare climate & grazing duration variables against effect size

## get last year grazed as covariate
meta.ready <- merge(meta3, gps.clim, by="uniqueID")
meta.ready[,"aridity"] <- (meta.ready$bio12)/(meta.ready$bio1+10)

#mixed-effects meta-analysis for grazed vs ungrazed plots
m3 <- rma(yi=yi, vi=vi, mods=~ -1 + aridity ,  data = meta.ready)
summary(m3) 

## Temperature
### calculate predicted risk ratios for full temperature gradient
preds <- predict(m3, newmods=c(0:110), transf=exp)

### radius of points will be proportional to the inverse standard errors
### hence the area of the points will be proportional to inverse variances
size <- 1 / sqrt(meta.ready$vi)
size <- size / max(size)

### set up plot (risk ratios on y-axis, absolute temperature on x-axis)
plot(NA, NA, xlim=c(0,110), ylim=c(0.2,10),
     xlab="Aridity", ylab="Risk Ratio",
     las=1, bty="l", log="y")

### add points
symbols(meta.ready$aridity, exp(meta.ready$yi), circles=size, inches=FALSE, add=TRUE, bg="black")
                   
### add predicted values (and corresponding CI bounds)
lines(0:110, preds$pred)
lines(0:110, preds$ci.lb, lty="dashed")
lines(0:110, preds$ci.ub, lty="dashed") 



### Precipitation

### calculate predicted risk ratios for full temperature gradient
preds <- predict(m3, newmods=c(400:1200), transf=exp)

### radius of points will be proportional to the inverse standard errors
### hence the area of the points will be proportional to inverse variances
size <- 1 / sqrt(meta.ready$vi)
size <- size / max(size)*10

### set up plot (risk ratios on y-axis, absolute temperature on x-axis)
plot(NA, NA, xlim=c(400,1200), ylim=c(0.2,10),
     xlab="Precipitation (mm)", ylab="Risk Ratio",
     las=1, bty="l", log="y")

### add points
symbols(meta.ready$bio12, exp(meta.ready$yi), circles=size, inches=FALSE, add=TRUE, bg="black")
                   
### add predicted values (and corresponding CI bounds)
lines(400:1200, preds$pred)
lines(400:1200, preds$ci.lb, lty="dashed")
lines(400:1200, preds$ci.ub, lty="dashed") 



## Time since grazed Grazed

## compare climate & grazing duration variables against effect size

## get last year grazed as covariate
meta.ready <- subset(meta3, yr.grazed>0& yr.grazed < 100)

#mixed-effects meta-analysis for grazed vs ungrazed plots
m3 <- rma(yi=yi, vi=vi, mods=~ -1 + yr.grazed ,  data = meta.ready)
summary(m3) 

## Temperature
### calculate predicted risk ratios for full temperature gradient
preds <- predict(m3, newmods=c(0:60), transf=exp)

### radius of points will be proportional to the inverse standard errors
### hence the area of the points will be proportional to inverse variances
size <- 1 / sqrt(meta.ready$vi)
size <- size / max(size)

### set up plot (risk ratios on y-axis, absolute temperature on x-axis)
plot(NA, NA, xlim=c(0,60), ylim=c(0.2,10),
     xlab="Year since last grazed", ylab="Risk Ratio",
     las=1, bty="l", log="y")

### add points
symbols(meta.ready$yr.grazed, exp(meta.ready$yi), circles=size, inches=FALSE, add=TRUE, bg="black")
                   
### add predicted values (and corresponding CI bounds)
lines(0:60, preds$pred)
lines(0:60, preds$ci.lb, lty="dashed")
lines(0:60, preds$ci.ub, lty="dashed") 
